{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2Seq model on ATIS dataset",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzE+kzBQVpAFakR67MQ/25",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romila95/Seq2Seq-NLU/blob/master/Seq2Seq_model_on_ATIS_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fNzxDO_sQg0",
        "colab_type": "text"
      },
      "source": [
        "# **SEQ2SEQ MODEL ON NLU**\n",
        "\n",
        "We implement a Seq2Seq model to acheve Intent Detection (ID) and Slot Filling (SF). The ID model tries to classify a user utterance into an intent, while the SF model tries to ﬁnd what are the “arguments” of such intent.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-i_y7nxvvNYD",
        "colab_type": "text"
      },
      "source": [
        "*Since we require to use the tensorflow contrib module, we use tensorflow version 1.14 instead of v2 which does not support the contrib module anymore*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iKDjtJ17Mqg8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "0319fd48-cf79-4f5f-d829-1303fc8211f6"
      },
      "source": [
        "# pip install tensorflow==1.14\n",
        "%tensorflow_version 1.14"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.14`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umSb5xM67cu0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUVOv7noZGMj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "02d7d780-4b6b-4aed-ff71-89c63f4d48dd"
      },
      "source": [
        "import tensorflow.contrib.eager as tfe\n",
        "tf.enable_eager_execution()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAFZa2oBaUN2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.compat.v1 as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrx1HSEBaSFX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "a8d838b6-2fcc-44f8-fe33-3f88ee812f98"
      },
      "source": [
        "tf.disable_v2_behavior()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/compat/v2_compat.py:68: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EcMtZCTuqPNZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b6RNdWC4vou3",
        "colab_type": "text"
      },
      "source": [
        "# **Load and Explore Dataset**\n",
        "\n",
        "The Airline Travel Information System (ATIS) dataset contains data obtained from the Official Airline Guide (OAG, 1990), organized under a relational schema. It contains information about flights, fares, airlines, cities, airports, and ground services, and includes twenty-five supporting tables. The large majority of the questions posed by subjects can be answered from the database with a single relational query."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVt_YFw4ro9c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "4e963af9-04a6-4904-93ed-89688ad1683d"
      },
      "source": [
        "import os\n",
        "print(os.listdir(\"atis\"))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['atis.test.query.csv', 'atis.dict.intent.csv', 'atis.train.query.csv', 'atis.train.intent.csv', 'atis.dict.vocab.csv', 'atis.test.pkl', 'atis.test.slots.csv', 'atis.test.intent.csv', 'atis.dict.slots.csv', 'atis.train.slots.csv', 'atis.train.pkl']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGpLSTOnsffU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "\n",
        "DATA_DIR=\"atis\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhCQinmKsg-G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load Pickle file \n",
        "def load_ds(fname=os.path.join(DATA_DIR,'/atis.train.pkl'), verbose=True):\n",
        "    with open(fname, 'rb') as stream:\n",
        "        ds,dicts = pickle.load(stream)\n",
        "    if verbose:\n",
        "      print('Done  loading: ', fname)\n",
        "      print('      samples: {:4d}'.format(len(ds['query'])))\n",
        "      print('   vocab_size: {:4d}'.format(len(dicts['token_ids'])))\n",
        "      print('   slot count: {:4d}'.format(len(dicts['slot_ids'])))\n",
        "      print(' intent count: {:4d}'.format(len(dicts['intent_ids'])))\n",
        "    return ds,dicts"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZHHkr4F0tfB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert Pickle file to arrays\n",
        "def load_atis(filename, add_start_end_token=False, verbose=True):\n",
        "    train_ds, dicts = load_ds(os.path.join(DATA_DIR,filename), verbose)\n",
        "    t2i, s2i, in2i = map(dicts.get, ['token_ids', 'slot_ids','intent_ids'])\n",
        "    i2t, i2s, i2in = map(lambda d: {d[k]:k for k in d.keys()}, [t2i,s2i,in2i])\n",
        "    query, slots, intent =  map(train_ds.get, ['query', 'slot_labels', 'intent_labels'])\n",
        "\n",
        "    if add_start_end_token:\n",
        "        i2s[178] = 'BOS'\n",
        "        i2s[179] = 'EOS'\n",
        "        s2i['BOS'] = 178\n",
        "        s2i['EOS'] = 179\n",
        "\n",
        "    input_tensor = []\n",
        "    target_tensor = []\n",
        "    query_data = []\n",
        "    intent_data = []\n",
        "    slot_data = []\n",
        "    to_show = np.random.randint(0, len(query)-1, 5)\n",
        "    for i in range(len(query)):\n",
        "        input_tensor.append(query[i])\n",
        "        slot_text = []\n",
        "        slot_vector = []\n",
        "        for j in range(len(query[i])):\n",
        "            slot_text.append(i2s[slots[i][j]])\n",
        "            slot_vector.append(slots[i][j])\n",
        "        if add_start_end_token:\n",
        "            slot_text[0] = 'BOS'\n",
        "            slot_vector[0] = 178\n",
        "            slot_text[-1] = 'EOS'\n",
        "            slot_vector[-1]= 179\n",
        "        target_tensor.append(slot_vector)\n",
        "        q = ' '.join(map(i2t.get, query[i]))\n",
        "        query_data.append(q.replace('BOS', '').replace('EOS',''))\n",
        "        intent_data.append(i2in[intent[i][0]])\n",
        "        slot = ' '.join(slot_text)\n",
        "        slot_data.append(slot[1:-1])\n",
        "        if i in to_show and verbose:\n",
        "          print('Query text:', q)\n",
        "          print('Query vector: ', query[i])\n",
        "          print('Intent label: ', i2in[intent[i][0]])\n",
        "          print('Slot text: ', slot)\n",
        "          print('Slot vector: ', slot_vector)\n",
        "          print('*'*74)\n",
        "    query_data = np.array(query_data)\n",
        "    intent_data = np.array(intent_data)\n",
        "    slot_data = np.array(slot_data)\n",
        "    intent_data_label = np.array(intent).flatten()\n",
        "    return t2i, s2i, in2i, i2t, i2s, i2in, input_tensor, target_tensor, query_data, intent_data, intent_data_label, slot_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J-GlrrDRsqCU",
        "colab_type": "text"
      },
      "source": [
        "# **Loading the Dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J17J8-EUs2p_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        },
        "outputId": "a4a7f52c-a58a-4643-9d7d-105d1f1aca61"
      },
      "source": [
        "# load ATIS training dataset\n",
        "t2i_train, s2i_train, in2i_train, i2t_train, i2s_train, i2in_train, \\\n",
        "input_tensor_train, target_tensor_train, \\\n",
        "query_data_train, intent_data_train, intent_data_label_train, slot_data_train = load_atis('atis.train.pkl')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  loading:  atis/atis.train.pkl\n",
            "      samples: 4978\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS what planes are used by twa EOS\n",
            "Query vector:  [178 916 686 228 892 277 877 179]\n",
            "Intent label:  aircraft\n",
            "Slot text:  O O O O O O B-airline_code O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 1, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS what types of ground transportation are available in philadelphia EOS\n",
            "Query vector:  [178 916 884 646 457 866 228 244 482 678 179]\n",
            "Intent label:  ground_service\n",
            "Slot text:  O O O O O O O O O B-city_name O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 128, 128, 17, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS the most expensive flight between boston and philadelphia EOS\n",
            "Query vector:  [178 827 608 407 428 259 266 215 678 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O B-cost_relative I-cost_relative O O B-fromloc.city_name O B-toloc.city_name O\n",
            "Slot vector:  [128, 128, 21, 93, 128, 128, 48, 128, 78, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS what airlines are there EOS\n",
            "Query vector:  [178 916 200 228 831 179]\n",
            "Intent label:  airline\n",
            "Slot text:  O O O O O O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS american flights to houston from cincinnati EOS\n",
            "Query vector:  [178 212 429 851 476 444 299 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O B-airline_name O O B-toloc.city_name O B-fromloc.city_name O\n",
            "Slot vector:  [128, 2, 128, 128, 78, 128, 48, 128]\n",
            "**************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzmfkUW118PD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "outputId": "0856f7be-14f5-43ac-8900-026f19e1e4ff"
      },
      "source": [
        "# load ATIS testing dataset\n",
        "t2i_test, s2i_test, in2i_test, i2t_test, i2s_test, i2in_test, \\\n",
        "input_tensor_test, target_tensor_test, \\\n",
        "query_data_test, intent_data_test, intent_data_label_test, slot_data_test = load_atis('atis.test.pkl')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done  loading:  atis/atis.test.pkl\n",
            "      samples:  893\n",
            "   vocab_size:  943\n",
            "   slot count:  129\n",
            " intent count:   26\n",
            "Query text: BOS which flights leave chicago next tuesday and arrive in detroit around 6 pm EOS\n",
            "Query vector:  [178 920 429 537 297 621 874 215 236 482 361 231 130 689 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-fromloc.city_name B-depart_date.date_relative B-depart_date.day_name O O O B-toloc.city_name B-arrive_time.time_relative B-arrive_time.time I-arrive_time.time O\n",
            "Slot vector:  [128, 128, 128, 128, 48, 25, 26, 128, 128, 128, 78, 15, 14, 89, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS show me all lufthansa flights from seattle to boston with stopovers in minneapolis EOS\n",
            "Query vector:  [178 770 581 207 568 429 444 752 851 266 925 799 482 597 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O B-airline_name O O B-fromloc.city_name O B-toloc.city_name O O O B-stoploc.city_name O\n",
            "Slot vector:  [128, 128, 128, 128, 2, 128, 128, 48, 128, 78, 128, 128, 128, 71, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS show me the cheapest round trip coach fare from las vegas to detroit EOS\n",
            "Query vector:  [178 770 581 827 296 730 870 308 414 444 527 897 851 361 179]\n",
            "Intent label:  airfare\n",
            "Slot text:  O O O O B-cost_relative B-round_trip I-round_trip B-class_type O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O\n",
            "Slot vector:  [128, 128, 128, 128, 21, 66, 119, 18, 128, 128, 48, 110, 128, 78, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS list all flights and their fares from indianapolis to memphis on a monday morning EOS\n",
            "Query vector:  [178 549 207 429 215 828 415 444 489 851 587 654 180 601 606 179]\n",
            "Intent label:  flight+airfare\n",
            "Slot text:  O O O O O O O O B-fromloc.city_name O B-toloc.city_name O O B-depart_date.day_name B-depart_time.period_of_day O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 128, 128, 48, 128, 78, 128, 128, 26, 33, 128]\n",
            "**************************************************************************\n",
            "Query text: BOS please list all flights from new york to miami any any type of class EOS\n",
            "Query vector:  [178 688 549 207 429 444 619 937 851 589 218 218 883 646 302 179]\n",
            "Intent label:  flight\n",
            "Slot text:  O O O O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name O O O O O O\n",
            "Slot vector:  [128, 128, 128, 128, 128, 128, 48, 110, 128, 78, 128, 128, 128, 128, 128, 128]\n",
            "**************************************************************************\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfWnobZ1tqDP",
        "colab_type": "text"
      },
      "source": [
        "# **Check few Samples**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YKulhjwJtw7u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "ee4c6dd8-917c-4c5b-d311-0fc125b18976"
      },
      "source": [
        "pd.set_option('display.max_colwidth', -1)\n",
        "df = pd.DataFrame({'query': query_data_train, 'intent': intent_data_train, 'slot filling': slot_data_train})\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: FutureWarning: Passing a negative integer is deprecated in version 1.0 and will not be supported in future version. Instead, use None to not limit the column width.\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aRQ9Aox2Pv6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b955489e-4d61-4289-b24f-18baaac06a62"
      },
      "source": [
        "df_small = pd.DataFrame(columns=['query','intent','slot filling'])\n",
        "j = 0\n",
        "for i in df.intent.unique():\n",
        "  df_small.loc[j] = df[df.intent==i].iloc[0]\n",
        "  j = j+1\n",
        "  \n",
        "df_small"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>query</th>\n",
              "      <th>intent</th>\n",
              "      <th>slot filling</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i want to fly from boston at 838 am and arrive in denver at 1110 in the morning</td>\n",
              "      <td>flight</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>what is the arrival time in san francisco for the 755 am flight leaving washington</td>\n",
              "      <td>flight_time</td>\n",
              "      <td>O O O B-flight_time I-flight_time O B-fromloc.city_name I-fromloc.city_name O O B-depart_time.time I-depart_time.time O O B-fromloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>cheapest airfare from tacoma to orlando</td>\n",
              "      <td>airfare</td>\n",
              "      <td>B-cost_relative O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>what kind of aircraft is used on a flight from cleveland to dallas</td>\n",
              "      <td>aircraft</td>\n",
              "      <td>O O O O O O O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>what kind of ground transportation is available in denver</td>\n",
              "      <td>ground_service</td>\n",
              "      <td>O O O O O O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>what 's the airport at orlando</td>\n",
              "      <td>airport</td>\n",
              "      <td>O O O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>which airline serves denver pittsburgh and atlanta</td>\n",
              "      <td>airline</td>\n",
              "      <td>O O O B-fromloc.city_name B-fromloc.city_name O B-fromloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>how far is it from orlando airport to orlando</td>\n",
              "      <td>distance</td>\n",
              "      <td>O O O O O B-fromloc.airport_name I-fromloc.airport_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>what is fare code h</td>\n",
              "      <td>abbreviation</td>\n",
              "      <td>O O O O B-fare_basis_code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>how much does the limousine service cost within pittsburgh</td>\n",
              "      <td>ground_fare</td>\n",
              "      <td>O O O O B-transport_type O O O B-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>please tell me how many nonstop flights there are from boston to atlanta</td>\n",
              "      <td>quantity</td>\n",
              "      <td>O O O O O B-flight_stop O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>what city is the airport mco in</td>\n",
              "      <td>city</td>\n",
              "      <td>O O O O O B-fromloc.airport_code O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>flight numbers from columbus to minneapolis tomorrow</td>\n",
              "      <td>flight_no</td>\n",
              "      <td>O O O B-fromloc.city_name O B-toloc.city_name B-depart_date.today_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>how many seats in a 100</td>\n",
              "      <td>capacity</td>\n",
              "      <td>O O O O O B-aircraft_code</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>give me the flights and fares on december twenty seventh from indianapolis to orlando</td>\n",
              "      <td>flight+airfare</td>\n",
              "      <td>O O O O O O O B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>show me all meals on flights from atlanta to washington</td>\n",
              "      <td>meal</td>\n",
              "      <td>O O O B-meal O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars</td>\n",
              "      <td>restriction</td>\n",
              "      <td>O O O O O O O O B-fromloc.city_name O B-toloc.city_name O O O O B-fare_amount I-fare_amount</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>airline and flight number from columbus to minneapolis</td>\n",
              "      <td>airline+flight_no</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>what ground transportation is available from the pittsburgh airport to downtown and how much does it cost</td>\n",
              "      <td>ground_service+ground_fare</td>\n",
              "      <td>O O O O O O O B-fromloc.airport_name I-fromloc.airport_name O O O O O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>show me the costs and times for flights from san francisco to atlanta</td>\n",
              "      <td>airfare+flight_time</td>\n",
              "      <td>O O O O O B-flight_time O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>show me the cheapest fare in the database</td>\n",
              "      <td>cheapest</td>\n",
              "      <td>O O O B-cost_relative O O O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number</td>\n",
              "      <td>aircraft+flight+flight_no</td>\n",
              "      <td>O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-airline_name I-airline_name O O B-depart_time.time_relative B-depart_time.time I-depart_time.time O O O O O O O O O O O O O O O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                     query  ...                                                                                                                                                                                               slot filling\n",
              "0    i want to fly from boston at 838 am and arrive in denver at 1110 in the morning                                                                                        ...   O O O O O B-fromloc.city_name O B-depart_time.time I-depart_time.time O O O B-toloc.city_name O B-arrive_time.time O O B-arrive_time.period_of_day                                                      \n",
              "1    what is the arrival time in san francisco for the 755 am flight leaving washington                                                                                     ...   O O O B-flight_time I-flight_time O B-fromloc.city_name I-fromloc.city_name O O B-depart_time.time I-depart_time.time O O B-fromloc.city_name                                                           \n",
              "2    cheapest airfare from tacoma to orlando                                                                                                                                ...   B-cost_relative O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                             \n",
              "3    what kind of aircraft is used on a flight from cleveland to dallas                                                                                                     ...   O O O O O O O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                             \n",
              "4    what kind of ground transportation is available in denver                                                                                                              ...   O O O O O O O O B-city_name                                                                                                                                                                             \n",
              "5    what 's the airport at orlando                                                                                                                                         ...   O O O O O B-city_name                                                                                                                                                                                   \n",
              "6    which airline serves denver pittsburgh and atlanta                                                                                                                     ...   O O O B-fromloc.city_name B-fromloc.city_name O B-fromloc.city_name                                                                                                                                     \n",
              "7    how far is it from orlando airport to orlando                                                                                                                          ...   O O O O O B-fromloc.airport_name I-fromloc.airport_name O B-toloc.city_name                                                                                                                             \n",
              "8    what is fare code h                                                                                                                                                    ...   O O O O B-fare_basis_code                                                                                                                                                                               \n",
              "9    how much does the limousine service cost within pittsburgh                                                                                                             ...   O O O O B-transport_type O O O B-city_name                                                                                                                                                              \n",
              "10   please tell me how many nonstop flights there are from boston to atlanta                                                                                               ...   O O O O O B-flight_stop O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                 \n",
              "11   what city is the airport mco in                                                                                                                                        ...   O O O O O B-fromloc.airport_code O                                                                                                                                                                      \n",
              "12   flight numbers from columbus to minneapolis tomorrow                                                                                                                   ...   O O O B-fromloc.city_name O B-toloc.city_name B-depart_date.today_relative                                                                                                                              \n",
              "13   how many seats in a 100                                                                                                                                                ...   O O O O O B-aircraft_code                                                                                                                                                                               \n",
              "14   give me the flights and fares on december twenty seventh from indianapolis to orlando                                                                                  ...   O O O O O O O B-depart_date.month_name B-depart_date.day_number I-depart_date.day_number O B-fromloc.city_name O B-toloc.city_name                                                                      \n",
              "15   show me all meals on flights from atlanta to washington                                                                                                                ...   O O O B-meal O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                              \n",
              "16   what are the air restrictions on flights from pittsburgh to atlanta for the airfare of 416 dollars                                                                     ...   O O O O O O O O B-fromloc.city_name O B-toloc.city_name O O O O B-fare_amount I-fare_amount                                                                                                             \n",
              "17   airline and flight number from columbus to minneapolis                                                                                                                 ...   O O O O O B-fromloc.city_name O B-toloc.city_name                                                                                                                                                       \n",
              "18   what ground transportation is available from the pittsburgh airport to downtown and how much does it cost                                                              ...   O O O O O O O B-fromloc.airport_name I-fromloc.airport_name O O O O O O O O                                                                                                                             \n",
              "19   show me the costs and times for flights from san francisco to atlanta                                                                                                  ...   O O O O O B-flight_time O O O B-fromloc.city_name I-fromloc.city_name O B-toloc.city_name                                                                                                               \n",
              "20   show me the cheapest fare in the database                                                                                                                              ...   O O O B-cost_relative O O O O                                                                                                                                                                           \n",
              "21   i want to fly from detroit to st. petersburg on northwest airlines and leave around 9 am tell me what aircraft are used by this flight and tell me the flight number   ...   O O O O O B-fromloc.city_name O B-toloc.city_name I-toloc.city_name O B-airline_name I-airline_name O O B-depart_time.time_relative B-depart_time.time I-depart_time.time O O O O O O O O O O O O O O O \n",
              "\n",
              "[22 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PDnQpVW3r_D",
        "colab_type": "text"
      },
      "source": [
        "For each instance in the intent column, the model is expected to categorize the intent into sections under the labels specified in the slot filling section.\n",
        "\n",
        "For example, in the first query, \"i want to fly from boston at 838 am and arrive in denver at 1110 in the morning\", the model should correctly label the entities needed to fulfill user’s goal in its intention to take a flight. These are “boston” as departure city (B-fromloc.city), “8:38 am” as departure time (B-depart_time.time), “denver” as destination city (B-toloc.city_name), “11:10” as arrival time (B-arrive_time.time) and “morning” as arrival period of day (B-arrive_time.period_of_day).\n",
        "\n",
        "Some of the labels are displayed below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XzDVwJt_t9-8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "ce290d7c-d03d-4b5b-ac31-4a8b70c092a5"
      },
      "source": [
        "i2s_train_values = list(i2s_train.values())\n",
        "df3 = pd.DataFrame()\n",
        "for i in range(7):\n",
        "  df3[str(i)] = i2s_train_values[i*15:(i+1)*15]\n",
        "df3"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B-aircraft_code</td>\n",
              "      <td>B-arrive_time.time_relative</td>\n",
              "      <td>B-depart_date.year</td>\n",
              "      <td>B-flight_time</td>\n",
              "      <td>B-return_date.day_name</td>\n",
              "      <td>B-today_relative</td>\n",
              "      <td>I-arrive_time.time_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B-airline_code</td>\n",
              "      <td>B-booking_class</td>\n",
              "      <td>B-depart_time.end_time</td>\n",
              "      <td>B-fromloc.airport_code</td>\n",
              "      <td>B-return_date.day_number</td>\n",
              "      <td>B-toloc.airport_code</td>\n",
              "      <td>I-city_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>B-airline_name</td>\n",
              "      <td>B-city_name</td>\n",
              "      <td>B-depart_time.period_mod</td>\n",
              "      <td>B-fromloc.airport_name</td>\n",
              "      <td>B-return_date.month_name</td>\n",
              "      <td>B-toloc.airport_name</td>\n",
              "      <td>I-class_type</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B-airport_code</td>\n",
              "      <td>B-class_type</td>\n",
              "      <td>B-depart_time.period_of_day</td>\n",
              "      <td>B-fromloc.city_name</td>\n",
              "      <td>B-return_date.today_relative</td>\n",
              "      <td>B-toloc.city_name</td>\n",
              "      <td>I-cost_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>B-airport_name</td>\n",
              "      <td>B-compartment</td>\n",
              "      <td>B-depart_time.start_time</td>\n",
              "      <td>B-fromloc.state_code</td>\n",
              "      <td>B-return_time.period_mod</td>\n",
              "      <td>B-toloc.country_name</td>\n",
              "      <td>I-depart_date.day_name</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>B-arrive_date.date_relative</td>\n",
              "      <td>B-connect</td>\n",
              "      <td>B-depart_time.time</td>\n",
              "      <td>B-fromloc.state_name</td>\n",
              "      <td>B-return_time.period_of_day</td>\n",
              "      <td>B-toloc.state_code</td>\n",
              "      <td>I-depart_date.day_number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>B-arrive_date.day_name</td>\n",
              "      <td>B-cost_relative</td>\n",
              "      <td>B-depart_time.time_relative</td>\n",
              "      <td>B-meal</td>\n",
              "      <td>B-round_trip</td>\n",
              "      <td>B-toloc.state_name</td>\n",
              "      <td>I-depart_date.today_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>B-arrive_date.day_number</td>\n",
              "      <td>B-day_name</td>\n",
              "      <td>B-economy</td>\n",
              "      <td>B-meal_code</td>\n",
              "      <td>B-state_code</td>\n",
              "      <td>B-transport_type</td>\n",
              "      <td>I-depart_time.end_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>B-arrive_date.month_name</td>\n",
              "      <td>B-day_number</td>\n",
              "      <td>B-fare_amount</td>\n",
              "      <td>B-meal_description</td>\n",
              "      <td>B-state_name</td>\n",
              "      <td>I-airline_name</td>\n",
              "      <td>I-depart_time.period_of_day</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>B-arrive_date.today_relative</td>\n",
              "      <td>B-days_code</td>\n",
              "      <td>B-fare_basis_code</td>\n",
              "      <td>B-mod</td>\n",
              "      <td>B-stoploc.airport_code</td>\n",
              "      <td>I-airport_name</td>\n",
              "      <td>I-depart_time.start_time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>B-arrive_time.end_time</td>\n",
              "      <td>B-depart_date.date_relative</td>\n",
              "      <td>B-flight</td>\n",
              "      <td>B-month_name</td>\n",
              "      <td>B-stoploc.airport_name</td>\n",
              "      <td>I-arrive_date.day_number</td>\n",
              "      <td>I-depart_time.time</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>B-arrive_time.period_mod</td>\n",
              "      <td>B-depart_date.day_name</td>\n",
              "      <td>B-flight_days</td>\n",
              "      <td>B-or</td>\n",
              "      <td>B-stoploc.city_name</td>\n",
              "      <td>I-arrive_time.end_time</td>\n",
              "      <td>I-depart_time.time_relative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>B-arrive_time.period_of_day</td>\n",
              "      <td>B-depart_date.day_number</td>\n",
              "      <td>B-flight_mod</td>\n",
              "      <td>B-period_of_day</td>\n",
              "      <td>B-stoploc.state_code</td>\n",
              "      <td>I-arrive_time.period_of_day</td>\n",
              "      <td>I-economy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>B-arrive_time.start_time</td>\n",
              "      <td>B-depart_date.month_name</td>\n",
              "      <td>B-flight_number</td>\n",
              "      <td>B-restriction_code</td>\n",
              "      <td>B-time</td>\n",
              "      <td>I-arrive_time.start_time</td>\n",
              "      <td>I-fare_amount</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>B-arrive_time.time</td>\n",
              "      <td>B-depart_date.today_relative</td>\n",
              "      <td>B-flight_stop</td>\n",
              "      <td>B-return_date.date_relative</td>\n",
              "      <td>B-time_relative</td>\n",
              "      <td>I-arrive_time.time</td>\n",
              "      <td>I-fare_basis_code</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                               0  ...                             6\n",
              "0   B-aircraft_code               ...  I-arrive_time.time_relative \n",
              "1   B-airline_code                ...  I-city_name                 \n",
              "2   B-airline_name                ...  I-class_type                \n",
              "3   B-airport_code                ...  I-cost_relative             \n",
              "4   B-airport_name                ...  I-depart_date.day_name      \n",
              "5   B-arrive_date.date_relative   ...  I-depart_date.day_number    \n",
              "6   B-arrive_date.day_name        ...  I-depart_date.today_relative\n",
              "7   B-arrive_date.day_number      ...  I-depart_time.end_time      \n",
              "8   B-arrive_date.month_name      ...  I-depart_time.period_of_day \n",
              "9   B-arrive_date.today_relative  ...  I-depart_time.start_time    \n",
              "10  B-arrive_time.end_time        ...  I-depart_time.time          \n",
              "11  B-arrive_time.period_mod      ...  I-depart_time.time_relative \n",
              "12  B-arrive_time.period_of_day   ...  I-economy                   \n",
              "13  B-arrive_time.start_time      ...  I-fare_amount               \n",
              "14  B-arrive_time.time            ...  I-fare_basis_code           \n",
              "\n",
              "[15 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S20SKRGI5kiZ",
        "colab_type": "text"
      },
      "source": [
        "# ** Creating Tensors**\n",
        "\n",
        "The query and slot filling vectors are padded to ax length for building tensors. Two sensors are provided for target, one is teacher tensor, which forces the decoder to follow a correct output slot and the other is the true target tensor, which defines what the decoder should output given the teacher tensor. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-9fT7DFu638m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_length(tensor):\n",
        "    return max(len(t) for t in tensor)\n",
        "\n",
        "# Helper function to pad the query tensor and slot (target) tensor to the same length. \n",
        "# Also creates a tensor for teacher forcing.\n",
        "def create_tensors(input_tensor, target_tensor, nb_sample=9999999, max_len=0):\n",
        "    len_input, len_target  = max_length(input_tensor), max_length(target_tensor)\n",
        "    len_input = max(len_input,max_len)\n",
        "    len_target = max(len_target,max_len)\n",
        "    \n",
        "\n",
        "    # Padding the input and output tensor to the maximum length\n",
        "    input_data = tf.keras.preprocessing.sequence.pad_sequences(input_tensor, \n",
        "                                                                 maxlen=len_input,\n",
        "                                                                 padding='post')\n",
        "\n",
        "    teacher_data = tf.keras.preprocessing.sequence.pad_sequences(target_tensor, \n",
        "                                                                  maxlen=len_target , \n",
        "                                                                  padding='post')\n",
        "    \n",
        "    target_data = [[teacher_data[n][i+1] for i in range(len(teacher_data[n])-1)] for n in range(len(teacher_data))]\n",
        "    target_data = tf.keras.preprocessing.sequence.pad_sequences(target_data, maxlen=len_target, padding=\"post\")\n",
        "    target_data = target_data.reshape((target_data.shape[0], target_data.shape[1], 1))\n",
        "    \n",
        "    nb = len(input_data)\n",
        "    p = np.random.permutation(nb)\n",
        "    input_data = input_data[p]\n",
        "    teacher_data = teacher_data[p]\n",
        "    target_data = target_data[p]\n",
        "\n",
        "    return input_data[:min(nb_sample, nb)], teacher_data[:min(nb_sample, nb)], target_data[:min(nb_sample, nb)], len_input, len_target \n",
        "           \n",
        "input_data_train, teacher_data_train, target_data_train, \\\n",
        "                  len_input_train, len_target_train  = create_tensors(input_tensor_train, target_tensor_train)\n",
        "input_data_test, teacher_data_test, target_data_test, \\\n",
        "                 len_input_test, len_target_test  = create_tensors(input_tensor_test, target_tensor_test, max_len=len_input_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7jyOZqF_7uvf",
        "colab_type": "text"
      },
      "source": [
        "Train and test vocabularies are combined to compute vocabulary size. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZOsrHVf7798",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e89f3cb1-3c0c-460e-ce8a-492ed928b93b"
      },
      "source": [
        "def get_vocab_size(t2i_train, t2i_test, s2i_train, s2i_test):\n",
        "    vocab_in_size = len({**t2i_train, **t2i_test})\n",
        "    vocab_out_size = len({**s2i_train, **s2i_test})\n",
        "    return vocab_in_size, vocab_out_size\n",
        "  \n",
        "vocab_in_size, vocab_out_size = get_vocab_size(t2i_train, t2i_test, s2i_train, s2i_test)\n",
        "vocab_in_size, vocab_out_size"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(943, 129)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LqYpi7Zn8B95",
        "colab_type": "text"
      },
      "source": [
        "# **Seq2Seq Model for Slot Filling**\n",
        "\n",
        "The model is created using a LSTM in the encoder and decoder. The input goes through an encoder model which gives the encoder output of shape (batch_size, max_length, hidden_size) and the encoder hidden state of shape (batch_size, hidden_size). Both encoder and decoders use an Embedding layer to project the sentences to learn a meaningful representation of the user query, which is fed to a unidirectional LSTM layer with 1024 cells."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDoouiQtA82x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f736acfc-c65e-4ddc-ead0-714c5d0ae2c3"
      },
      "source": [
        "from keras.layers import Input, Embedding, Dense, Dropout, LSTM\n",
        "from keras.models import Model"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1QWD5tvUDwr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tf.reset_default_graph()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GtQlJW339DQX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 598
        },
        "outputId": "d8e84a53-2c03-46d0-9e24-519a900fe31b"
      },
      "source": [
        "BUFFER_SIZE = len(input_data_train)\n",
        "BATCH_SIZE = 64\n",
        "N_BATCH = BUFFER_SIZE//BATCH_SIZE\n",
        "embedding_dim = 256\n",
        "units = 1024\n",
        "\n",
        "# Create the Encoder layers first.\n",
        "encoder_inputs = Input(shape=(len_input_train,))\n",
        "encoder_emb = Embedding(input_dim=vocab_in_size, output_dim=embedding_dim)\n",
        "encoder_lstm = LSTM(units=units, return_sequences=True, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(encoder_emb(encoder_inputs))\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Now create the Decoder layers.\n",
        "decoder_inputs = Input(shape=(None,))\n",
        "decoder_emb = Embedding(input_dim=vocab_out_size, output_dim=embedding_dim)\n",
        "decoder_lstm = LSTM(units=units, return_sequences=True, return_state=True)\n",
        "decoder_lstm_out, _, _ = decoder_lstm(decoder_emb(decoder_inputs), initial_state=encoder_states)\n",
        "# Two dense layers to improve inference capabilities.\n",
        "decoder_d1 = Dense(units, activation=\"relu\")\n",
        "decoder_d2 = Dense(vocab_out_size, activation=\"softmax\")\n",
        "# Drop-out is added in the dense layers to help mitigate overfitting in this part of the model.\n",
        "decoder_out = decoder_d2(Dropout(rate=.4)(decoder_d1(Dropout(rate=.4)(decoder_lstm_out))))\n",
        "\n",
        "# Finally, create a training model which combines the encoder and the decoder.\n",
        "# Note that this model has three inputs:\n",
        "#  encoder_inputs=[batch,encoded_words] from input (query)\n",
        "#  decoder_inputs=[batch,encoded_words] from output (slots). This is the \"teacher tensor\".\n",
        "#  decoder_out=[batch,encoded_words] from output (slots). This is the \"target tensor\".\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_out)\n",
        "# Use sparse_categorical_crossentropy so we don't have to expand decoder_out into a massive one-hot array.\n",
        "model.compile(optimizer=tf.train.AdamOptimizer(), loss=\"sparse_categorical_crossentropy\", metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 48)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None)         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, 48, 256)      241408      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_2 (Embedding)         (None, None, 256)    33024       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, 48, 1024), ( 5246976     embedding_1[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "lstm_2 (LSTM)                   [(None, None, 1024), 5246976     embedding_2[0][0]                \n",
            "                                                                 lstm_1[0][1]                     \n",
            "                                                                 lstm_1[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, None, 1024)   0           lstm_2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 1024)   1049600     dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dropout_1 (Dropout)             (None, None, 1024)   0           dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 129)    132225      dropout_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 11,950,209\n",
            "Trainable params: 11,950,209\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nzvTG6nPLWN",
        "colab_type": "text"
      },
      "source": [
        "**Training the Seq2Seq Model**\n",
        "\n",
        "Since our target vectors are not one-hot encoded, we use sparse categorical crossentropy as loss function. With Adam as optimizer in 50 epochs, we use 3982 training samples, and 996 validation samples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeyPBvUoUz5N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import torch\n",
        "\n",
        "#device = torch.device(\"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoCM-xmDdIDJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tensorflow.contrib.rnn import *"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38mZLJQoNDjo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1d7b5cea-67fb-4ac0-9321-e042017e0ab8"
      },
      "source": [
        "epochs = 50\n",
        "history = model.fit([input_data_train, teacher_data_train], target_data_train,batch_size=BATCH_SIZE,epochs=epochs,validation_data=([input_data_test, teacher_data_test], target_data_test))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:431: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:438: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "Train on 4978 samples, validate on 893 samples\n",
            "Epoch 1/50\n",
            "4978/4978 [==============================] - 613s 123ms/step - loss: 0.8951 - sparse_categorical_accuracy: 0.8539 - val_loss: 0.5356 - val_sparse_categorical_accuracy: 0.8906\n",
            "Epoch 2/50\n",
            "4978/4978 [==============================] - 612s 123ms/step - loss: 0.4409 - sparse_categorical_accuracy: 0.8975 - val_loss: 0.3634 - val_sparse_categorical_accuracy: 0.9171\n",
            "Epoch 3/50\n",
            "4978/4978 [==============================] - 617s 124ms/step - loss: 0.3441 - sparse_categorical_accuracy: 0.9176 - val_loss: 0.3049 - val_sparse_categorical_accuracy: 0.9235\n",
            "Epoch 4/50\n",
            "4978/4978 [==============================] - 647s 130ms/step - loss: 0.3087 - sparse_categorical_accuracy: 0.9229 - val_loss: 0.2842 - val_sparse_categorical_accuracy: 0.9288\n",
            "Epoch 5/50\n",
            "4978/4978 [==============================] - 644s 129ms/step - loss: 0.2908 - sparse_categorical_accuracy: 0.9266 - val_loss: 0.2747 - val_sparse_categorical_accuracy: 0.9291\n",
            "Epoch 6/50\n",
            "4978/4978 [==============================] - 637s 128ms/step - loss: 0.2804 - sparse_categorical_accuracy: 0.9291 - val_loss: 0.2693 - val_sparse_categorical_accuracy: 0.9312\n",
            "Epoch 7/50\n",
            "4978/4978 [==============================] - 624s 125ms/step - loss: 0.2727 - sparse_categorical_accuracy: 0.9301 - val_loss: 0.2641 - val_sparse_categorical_accuracy: 0.9322\n",
            "Epoch 8/50\n",
            "4978/4978 [==============================] - 623s 125ms/step - loss: 0.2678 - sparse_categorical_accuracy: 0.9305 - val_loss: 0.2611 - val_sparse_categorical_accuracy: 0.9329\n",
            "Epoch 9/50\n",
            "4978/4978 [==============================] - 636s 128ms/step - loss: 0.2634 - sparse_categorical_accuracy: 0.9312 - val_loss: 0.2580 - val_sparse_categorical_accuracy: 0.9325\n",
            "Epoch 10/50\n",
            "4978/4978 [==============================] - 644s 129ms/step - loss: 0.2595 - sparse_categorical_accuracy: 0.9319 - val_loss: 0.2544 - val_sparse_categorical_accuracy: 0.9330\n",
            "Epoch 11/50\n",
            "4978/4978 [==============================] - 644s 129ms/step - loss: 0.2558 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.2528 - val_sparse_categorical_accuracy: 0.9335\n",
            "Epoch 12/50\n",
            "4978/4978 [==============================] - 628s 126ms/step - loss: 0.2535 - sparse_categorical_accuracy: 0.9323 - val_loss: 0.2512 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 13/50\n",
            "4978/4978 [==============================] - 626s 126ms/step - loss: 0.2508 - sparse_categorical_accuracy: 0.9330 - val_loss: 0.2507 - val_sparse_categorical_accuracy: 0.9331\n",
            "Epoch 14/50\n",
            "4978/4978 [==============================] - 634s 127ms/step - loss: 0.2484 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.2510 - val_sparse_categorical_accuracy: 0.9335\n",
            "Epoch 15/50\n",
            "4978/4978 [==============================] - 648s 130ms/step - loss: 0.2467 - sparse_categorical_accuracy: 0.9334 - val_loss: 0.2525 - val_sparse_categorical_accuracy: 0.9336\n",
            "Epoch 16/50\n",
            "4978/4978 [==============================] - 654s 131ms/step - loss: 0.2449 - sparse_categorical_accuracy: 0.9338 - val_loss: 0.2500 - val_sparse_categorical_accuracy: 0.9331\n",
            "Epoch 17/50\n",
            "4978/4978 [==============================] - 642s 129ms/step - loss: 0.2427 - sparse_categorical_accuracy: 0.9340 - val_loss: 0.2493 - val_sparse_categorical_accuracy: 0.9333\n",
            "Epoch 18/50\n",
            "4978/4978 [==============================] - 638s 128ms/step - loss: 0.2399 - sparse_categorical_accuracy: 0.9344 - val_loss: 0.2482 - val_sparse_categorical_accuracy: 0.9330\n",
            "Epoch 19/50\n",
            "4978/4978 [==============================] - 631s 127ms/step - loss: 0.2391 - sparse_categorical_accuracy: 0.9342 - val_loss: 0.2496 - val_sparse_categorical_accuracy: 0.9333\n",
            "Epoch 20/50\n",
            "4978/4978 [==============================] - 630s 127ms/step - loss: 0.2350 - sparse_categorical_accuracy: 0.9348 - val_loss: 0.2429 - val_sparse_categorical_accuracy: 0.9355\n",
            "Epoch 21/50\n",
            "4978/4978 [==============================] - 640s 129ms/step - loss: 0.2182 - sparse_categorical_accuracy: 0.9399 - val_loss: 0.2267 - val_sparse_categorical_accuracy: 0.9413\n",
            "Epoch 22/50\n",
            "4978/4978 [==============================] - 640s 129ms/step - loss: 0.2046 - sparse_categorical_accuracy: 0.9429 - val_loss: 0.2184 - val_sparse_categorical_accuracy: 0.9416\n",
            "Epoch 23/50\n",
            "4978/4978 [==============================] - 626s 126ms/step - loss: 0.1933 - sparse_categorical_accuracy: 0.9446 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 24/50\n",
            "4978/4978 [==============================] - 627s 126ms/step - loss: 0.1866 - sparse_categorical_accuracy: 0.9463 - val_loss: 0.2133 - val_sparse_categorical_accuracy: 0.9452\n",
            "Epoch 25/50\n",
            "4978/4978 [==============================] - 628s 126ms/step - loss: 0.1811 - sparse_categorical_accuracy: 0.9470 - val_loss: 0.2089 - val_sparse_categorical_accuracy: 0.9456\n",
            "Epoch 26/50\n",
            "4978/4978 [==============================] - 634s 127ms/step - loss: 0.1753 - sparse_categorical_accuracy: 0.9486 - val_loss: 0.2071 - val_sparse_categorical_accuracy: 0.9460\n",
            "Epoch 27/50\n",
            "4978/4978 [==============================] - 646s 130ms/step - loss: 0.1729 - sparse_categorical_accuracy: 0.9487 - val_loss: 0.2101 - val_sparse_categorical_accuracy: 0.9454\n",
            "Epoch 28/50\n",
            "4978/4978 [==============================] - 650s 131ms/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9493 - val_loss: 0.2110 - val_sparse_categorical_accuracy: 0.9463\n",
            "Epoch 29/50\n",
            "4978/4978 [==============================] - 652s 131ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9500 - val_loss: 0.2135 - val_sparse_categorical_accuracy: 0.9446\n",
            "Epoch 30/50\n",
            "4978/4978 [==============================] - 642s 129ms/step - loss: 0.1628 - sparse_categorical_accuracy: 0.9504 - val_loss: 0.2168 - val_sparse_categorical_accuracy: 0.9437\n",
            "Epoch 31/50\n",
            "4978/4978 [==============================] - 634s 127ms/step - loss: 0.1602 - sparse_categorical_accuracy: 0.9510 - val_loss: 0.2130 - val_sparse_categorical_accuracy: 0.9450\n",
            "Epoch 32/50\n",
            "4978/4978 [==============================] - 644s 129ms/step - loss: 0.1577 - sparse_categorical_accuracy: 0.9513 - val_loss: 0.2154 - val_sparse_categorical_accuracy: 0.9448\n",
            "Epoch 33/50\n",
            "4978/4978 [==============================] - 646s 130ms/step - loss: 0.1566 - sparse_categorical_accuracy: 0.9515 - val_loss: 0.2163 - val_sparse_categorical_accuracy: 0.9449\n",
            "Epoch 34/50\n",
            "4978/4978 [==============================] - 637s 128ms/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9528 - val_loss: 0.2197 - val_sparse_categorical_accuracy: 0.9438\n",
            "Epoch 35/50\n",
            "4978/4978 [==============================] - 627s 126ms/step - loss: 0.1494 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.2210 - val_sparse_categorical_accuracy: 0.9451\n",
            "Epoch 36/50\n",
            "4978/4978 [==============================] - 631s 127ms/step - loss: 0.1478 - sparse_categorical_accuracy: 0.9534 - val_loss: 0.2217 - val_sparse_categorical_accuracy: 0.9440\n",
            "Epoch 37/50\n",
            "4978/4978 [==============================] - 637s 128ms/step - loss: 0.1470 - sparse_categorical_accuracy: 0.9538 - val_loss: 0.2236 - val_sparse_categorical_accuracy: 0.9436\n",
            "Epoch 38/50\n",
            "4978/4978 [==============================] - 645s 129ms/step - loss: 0.1432 - sparse_categorical_accuracy: 0.9546 - val_loss: 0.2274 - val_sparse_categorical_accuracy: 0.9438\n",
            "Epoch 39/50\n",
            "4978/4978 [==============================] - 639s 128ms/step - loss: 0.1406 - sparse_categorical_accuracy: 0.9552 - val_loss: 0.2285 - val_sparse_categorical_accuracy: 0.9453\n",
            "Epoch 40/50\n",
            "4978/4978 [==============================] - 629s 126ms/step - loss: 0.1364 - sparse_categorical_accuracy: 0.9559 - val_loss: 0.2306 - val_sparse_categorical_accuracy: 0.9448\n",
            "Epoch 41/50\n",
            "4978/4978 [==============================] - 622s 125ms/step - loss: 0.1338 - sparse_categorical_accuracy: 0.9570 - val_loss: 0.2330 - val_sparse_categorical_accuracy: 0.9455\n",
            "Epoch 42/50\n",
            "4978/4978 [==============================] - 620s 125ms/step - loss: 0.1309 - sparse_categorical_accuracy: 0.9577 - val_loss: 0.2304 - val_sparse_categorical_accuracy: 0.9465\n",
            "Epoch 43/50\n",
            "4978/4978 [==============================] - 625s 126ms/step - loss: 0.1289 - sparse_categorical_accuracy: 0.9584 - val_loss: 0.2346 - val_sparse_categorical_accuracy: 0.9466\n",
            "Epoch 44/50\n",
            "4978/4978 [==============================] - 632s 127ms/step - loss: 0.1272 - sparse_categorical_accuracy: 0.9588 - val_loss: 0.2331 - val_sparse_categorical_accuracy: 0.9455\n",
            "Epoch 45/50\n",
            "4978/4978 [==============================] - 655s 132ms/step - loss: 0.1247 - sparse_categorical_accuracy: 0.9593 - val_loss: 0.2371 - val_sparse_categorical_accuracy: 0.9453\n",
            "Epoch 46/50\n",
            "4978/4978 [==============================] - 664s 133ms/step - loss: 0.1228 - sparse_categorical_accuracy: 0.9600 - val_loss: 0.2340 - val_sparse_categorical_accuracy: 0.9441\n",
            "Epoch 47/50\n",
            "4978/4978 [==============================] - 646s 130ms/step - loss: 0.1180 - sparse_categorical_accuracy: 0.9611 - val_loss: 0.2257 - val_sparse_categorical_accuracy: 0.9472\n",
            "Epoch 48/50\n",
            "4978/4978 [==============================] - 640s 129ms/step - loss: 0.1098 - sparse_categorical_accuracy: 0.9639 - val_loss: 0.2118 - val_sparse_categorical_accuracy: 0.9497\n",
            "Epoch 49/50\n",
            "4978/4978 [==============================] - 654s 131ms/step - loss: 0.1035 - sparse_categorical_accuracy: 0.9658 - val_loss: 0.2086 - val_sparse_categorical_accuracy: 0.9516\n",
            "Epoch 50/50\n",
            "4978/4978 [==============================] - 652s 131ms/step - loss: 0.0999 - sparse_categorical_accuracy: 0.9668 - val_loss: 0.2101 - val_sparse_categorical_accuracy: 0.9522\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVd0WIqHU4YI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0X8B4wgW61K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z35pP4kFSmt-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "226752aa-f573-489f-b2f5-3cec4cf87685"
      },
      "source": [
        "def plot_training_accuracy(history):\n",
        "\n",
        "  acc = history.history['sparse_categorical_accuracy']\n",
        "  val_acc = history.history['val_sparse_categorical_accuracy']\n",
        "\n",
        "  epochs = range(1, len(acc) + 1)\n",
        "\n",
        "  plt.plot(epochs, acc, 'bo', label='Training accuracy')\n",
        "  plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
        "  plt.title('Training and validation accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "plot_training_accuracy(history)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCmrOr0vw9Rh",
        "colab_type": "text"
      },
      "source": [
        "# **Accuracies**\n",
        "\n",
        "We find 98% accuracy on the training data and a validation accuracy just below 96%. The validation accuracy is optimum around epoch 45 and starts to overfit beyond that level."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeLi0Jv5x0XL",
        "colab_type": "text"
      },
      "source": [
        "#**Inference**\n",
        "\n",
        "Prediction will require two separate models from training. We need to break up the encoder and decoder mechanisms. We then run the entire input sequence through the encoder, then create the output by predicting with the decoder one step at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y16toeDeg4lm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6b69c376-0c53-4d9f-a075-950307448760"
      },
      "source": [
        "# Create the encoder model from the tensors we previously declared.\n",
        "encoder_model = Model(encoder_inputs, [encoder_outputs, state_h, state_c])\n",
        "\n",
        "# Generate a new set of tensors for our new inference decoder. Note that we are using new tensors, \n",
        "# this does not preclude using the same underlying layers that we trained on. (e.g. weights/biases).\n",
        "inf_decoder_inputs = Input(shape=(None,), name=\"inf_decoder_inputs\")\n",
        "# We'll need to force feed the two state variables into the decoder each step.\n",
        "state_input_h = Input(shape=(units,), name=\"state_input_h\")\n",
        "state_input_c = Input(shape=(units,), name=\"state_input_c\")\n",
        "decoder_res, decoder_h, decoder_c = decoder_lstm(\n",
        "    decoder_emb(inf_decoder_inputs), \n",
        "    initial_state=[state_input_h, state_input_c])\n",
        "inf_decoder_out = decoder_d2(decoder_d1(decoder_res))\n",
        "inf_model = Model(inputs=[inf_decoder_inputs, state_input_h, state_input_c], \n",
        "                  outputs=[inf_decoder_out, decoder_h, decoder_c])\n",
        "                  \n",
        "def preprocess_query(w):\n",
        "    w = w.rstrip().strip().lower()\n",
        "    w = \"BOS \" + w + \" EOS\"\n",
        "    return w\n",
        "  \n",
        "# Converts the given query (just a string) into a vector of word IDs\n",
        "# using the language specified. This can be used for either the input (query)\n",
        "# or target (slot)\n",
        "# Output is 1-D: [timesteps/words]\n",
        "def query_to_vector(query, len_input=len_input_train, t2i=t2i_train):\n",
        "    pre = preprocess_query(query)\n",
        "    vec = np.zeros(len_input)\n",
        "    query_list = [t2i[s] for s in pre.split(' ')]\n",
        "    for i,w in enumerate(query_list):\n",
        "        vec[i] = w\n",
        "    return vec\n",
        "\n",
        "# Given an input string, an encoder model (infenc_model) and a decoder model (infmodel),\n",
        "# return a predicted slot string.\n",
        "def predict_slots(input_query, infenc_model, infmodel, \n",
        "                  len_input=len_input_train, \n",
        "                  t2i=t2i_train, s2i=s2i_train, i2s=i2s_train,\n",
        "                  len_target=len_target_train,\n",
        "                  attention=False):\n",
        "    sent_len = len(input_query.split())\n",
        "    sv = query_to_vector(input_query, len_input, t2i)\n",
        "    # Reshape so we can use the encoder model. New shape=[samples,sequence length]\n",
        "    sv = sv.reshape(1,len(sv))\n",
        "    [emb_out, sh, sc] = infenc_model.predict(x=sv)\n",
        "    \n",
        "    i = 0\n",
        "    start_vec = s2i[\"O\"]\n",
        "    stop_vec = s2i[\"O\"]\n",
        "    # We will continuously feed cur_vec as an input into the decoder to produce the next word,\n",
        "    # which will be assigned to cur_vec. Start it with \"EOS\".\n",
        "    cur_vec = np.zeros((1,1))\n",
        "    cur_vec[0,0] = start_vec\n",
        "    cur_word = \"BOS\"\n",
        "    output_query = \"\"\n",
        "    # Start doing the feeding. Terminate when the model predicts an \"EOS\" or we reach the end\n",
        "    # of the max target slot length.\n",
        "    while cur_word != \"EOS\" and i < (len_target-1) and i < sent_len+1:\n",
        "        i += 1\n",
        "        if cur_word != \"BOS\":\n",
        "            output_query = output_query + \" \" + cur_word\n",
        "        x_in = [cur_vec, sh, sc]\n",
        "        # This will allow us to accomodate attention models, which we will talk about later.\n",
        "        if attention:\n",
        "            x_in += [emb_out]\n",
        "        [nvec, sh, sc] = infmodel.predict(x=x_in)\n",
        "        # The output of the model is a massive softmax vector with one spot for every possible word. Convert\n",
        "        # it to a word ID using argmax().\n",
        "        cur_vec[0,0] = np.argmax(nvec[0,0])\n",
        "        cur_word = i2s[np.argmax(nvec[0,0])]\n",
        "    return output_query\n",
        "    \n",
        "input_query = \"what is the cheapest flight from boston to san francisco\"\n",
        "print(predict_slots(input_query, encoder_model, inf_model))\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " O O O B-cost_relative O O B-fromloc.city_name O B-toloc.city_name O\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yHIApGjpPdV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.translate.bleu_score import corpus_bleu"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gLH9PlZ1n9Lc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "d92055c7-7d61-4cb5-e05f-e82853c5edc1"
      },
      "source": [
        "def evaluate_slot_filling(queries, true_slots,\n",
        "                          len_input=len_input_test, \n",
        "                          t2i=t2i_test, s2i=s2i_test, i2s=i2s_test,\n",
        "                          len_target=len_target_test):\n",
        "  predicted_slots = []\n",
        "  for q in queries:\n",
        "    s = predict_slots(q, encoder_model, inf_model,\n",
        "                      len_input, \n",
        "                      t2i, s2i, i2s,\n",
        "                      len_target)\n",
        "    predicted_slots.append(s)\n",
        "  # calculate BLEU score\n",
        "  print('BLEU-1: %f' % corpus_bleu(true_slots, predicted_slots, weights=(1.0, 0, 0, 0)))\n",
        "  print('BLEU-2: %f' % corpus_bleu(true_slots, predicted_slots, weights=(0.5, 0.5, 0, 0)))\n",
        "  print('BLEU-3: %f' % corpus_bleu(true_slots, predicted_slots, weights=(0.3, 0.3, 0.3, 0)))\n",
        "  print('BLEU-4: %f' % corpus_bleu(true_slots, predicted_slots, weights=(0.25, 0.25, 0.25, 0.25)))\n",
        "  \n",
        "evaluate_slot_filling(query_data_test, slot_data_test)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "BLEU-1: 0.231750\n",
            "BLEU-2: 0.481404\n",
            "BLEU-3: 0.644920\n",
            "BLEU-4: 0.693833\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D6mi9zGHqdO1",
        "colab_type": "text"
      },
      "source": [
        "The model performs best with a BLEU of 69.4% when comparing between 4-grams of predicted and true slots followed by a BLEU of 64.5% for 3-grams."
      ]
    }
  ]
}